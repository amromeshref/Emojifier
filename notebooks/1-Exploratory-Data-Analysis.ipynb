{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b1c562",
   "metadata": {},
   "source": [
    "#### General Steps to Follow\n",
    "\n",
    "1. Problem Statement\n",
    "2. Importing Packages\n",
    "3. Data Collection\n",
    "4. Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94d173",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266f761",
   "metadata": {},
   "source": [
    "## 1) Problem statement\n",
    "- I will implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence(⚾️)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719566fb",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff151f",
   "metadata": {},
   "source": [
    "## 2) Importing Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b3094b",
   "metadata": {},
   "source": [
    "#### Add the repository directory path to the Python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85154d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "REPO_DIR_PATH = os.path.normpath(os.path.join(\n",
    "    os.path.join(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "sys.path.append(REPO_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9319dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.utils import read_glove_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace9178",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46572459",
   "metadata": {},
   "source": [
    "## 3) Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428072e",
   "metadata": {},
   "source": [
    "- I used the dataset from the \"Sequence Models\" course in the \"Deep Learning\" Specialization on Coursera.\n",
    "- The dataset (X, Y) where:\n",
    "    - X contains sentences (strings).\n",
    "    - Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
    "- The dataset is located at `data/emojify_data.csv`\n",
    "- I will also use a pre-trained set of word embeddings, specifically 50-dimensional GloVe vectors, to represent each word. The embeddings are saved at `data/glove.6B.50d.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab6181",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../images/data_set.png\" alt=\"Description of the image\" width=800 height = 800>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de427cb",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f892520",
   "metadata": {},
   "source": [
    "## 4) Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7a1318",
   "metadata": {},
   "source": [
    "#### Checking the Emojifier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3087788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/emojify_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c55c8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>French macaroon is so tasty</th>\n",
       "      <th>4</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is your favorite baseball game</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           French macaroon is so tasty  4  Unnamed: 2 Unnamed: 3\n",
       "0                     work is horrible  3         NaN        NaN\n",
       "1                           I am upset  3         NaN        [3]\n",
       "2                       throw the ball  1         NaN        [2]\n",
       "3                            Good joke  2         NaN        NaN\n",
       "4  what is your favorite baseball game  1         NaN        NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8cca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19218d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "max_length_sentence = 0\n",
    "for i in range(len(data)):\n",
    "    max_length_sentence = max(len(data.iloc[:,0][i].split()),max_length_sentence)\n",
    "print(max_length_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbee8ee",
   "metadata": {},
   "source": [
    "- The data consists of 182 sentences along with their corresponding label. \n",
    "- The sentences in the dataset contain a maximum of 10 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f7130f",
   "metadata": {},
   "source": [
    "#### Checking the Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5506dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"../data/glove.6B.50d.txt\"\n",
    "words, word_to_vec_map = read_glove_vectors(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97022c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2572ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0cffcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"the\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a56c73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89855 ,  0.30093 ,  0.38384 , -0.07748 ,  1.2406  ,  0.6338  ,\n",
       "       -0.49759 ,  0.59377 , -0.16398 , -0.079284,  0.6614  , -0.17841 ,\n",
       "        0.064431,  0.15498 ,  0.63783 , -0.12535 , -0.045814,  0.084162,\n",
       "       -0.84272 ,  0.25469 , -0.53641 ,  0.058337,  0.53229 ,  0.60801 ,\n",
       "        0.41529 , -1.2192  , -1.1077  , -0.29251 ,  0.50284 ,  0.65703 ,\n",
       "        2.2331  , -1.2356  ,  0.18461 , -1.1709  ,  0.56209 ,  0.3741  ,\n",
       "        0.24536 , -0.21032 , -0.35088 ,  0.20336 ,  0.098822, -0.15596 ,\n",
       "        0.088795,  0.17909 ,  0.21729 , -0.50994 , -0.48693 , -0.07791 ,\n",
       "        0.55245 , -0.62789 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vec_map[\"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25f85ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc145d2",
   "metadata": {},
   "source": [
    "- There are 400000 words along with their embedding vector\n",
    "- There is a vector to handle unknown words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai1",
   "language": "python",
   "name": "ai1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
